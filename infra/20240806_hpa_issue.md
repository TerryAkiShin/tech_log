# HPA(Horizontal-Pod-AutoScaler)

[k8s autoscaler](https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md)

[EKS 공식문서 From AWS](https://docs.aws.amazon.com/ko_kr/eks/latest/userguide/horizontal-pod-autoscaler.html)

### 기본 개념
* 고용성을 위해 pod를 scale up 하는 방법 중에서 `수평적`으로 Pod를 증가시키는 방법
* 수평적으로 증가하는 것을 Scale Out, 줄어두는 것은 Scale In
* 사용이 권장되는 경우
    * Stateless App : 양적인 증가를 하기에 적합한 앱
    * 파드의 장애 발생 시 빠르게 기동 되어야 하는 앱

<br>

### 비교하기
* VPA(Vertical Pod Autoscaler)
* CA(Cluster Autoscaler)

<br>

### HPA 동작원리
1. Pod는 Control plane node에 있는 Metric Server로 메트릭 지표를 전송한다. 기본적으로 통신이 가능하도록 EKS 구성시 네트워크 설정을 잡아주어야 한다.
2. HPA는 EKS Cluster가 떠있는 VPC Node 내에서 아래와 같이 동작한다.
    1. Metric Server로 Get 요청을 보내서 Pod의 상태정보를 가져온다. 엔드포인트는 `api/metirics/v1alpha1/`의 하위에 아래와 같은 path가 붙는다.
        * /nodes : 모든 노드의 메트릭
        * /nodes/{node} : 특정 노드의 메트릭
        * /namespaces/{namespace}/pods : 특정 네임스페이스에 속한 모든 pod의 메트릭
        * /namespaces/{namespace}/pods/{pod} : 특정 네임스페이스에 속한 특정 pod의 메트릭
    2. 기준을 적용하여 레플리카의 갯수를 계산한다. 15초 마다 수행한다고 함
    3. 레플리카가 필요한 경우 Control plane node를 통해서 rollout을 통해 pod를 생성하거나 소멸함

<br>

### HPA 적용 방법
1. metric server 설치
2. hpa 설정
3. cluster 내 띄우기

<br>

* 직접 설치
```SHELL
# Non HA Deployment
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.7.1/components.yaml

# HA Deployment
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.7.1/high-availability.yaml
```

<br>

* 헬름차트로 설치
```SHELL
# add the metrics-server repo
helm repo add metrics-server https://kubernetes-sigs.github.io/metrics-server/

# install the chart
helm upgrade --install metrics-server metrics-server/metrics-server
```

<br>

* 설치확인
```SHELL
# List all HPA
kubectl get hpa -W

# List specific HPA
kubectl get hpa hpa-demo-deployment 

# Describe HPA
kubectl describe hpa/hpa-demo-deployment 

# List Pods
kubectl get pods
```

<br>

* 설정하기
```SHELL
kubectl edit deployment/metrics-server -n kube-system
```

<br>

* 명령형으로 선언하여 CPU utilization metric 설정
```SHELL
kubectl patch deployment php-apache -p='{"spec":{"template":{"spec":{"containers":[{"name":"hpa-example","resources":{"requests":{"cpu":"200m"}}}]}}}}'
deployment.apps/php-apache patched
```

<br>

* 선언형으로 선언하기
    * 아래 내용에서 기본 설정은 아래와 같다.
        * minReplicas: 최소 pod 수
        * maxReplicas: 최대 pod 수
        * metrics : replica's를 계산하기 위한 기준 메트릭 지표이다. 아래는 cpu 사용량 50이다. 메트릭의 경우 Memory, packets-per-second와 같은 다른 값들도 존재하며 Utilization 외에도 AverageValue 같은 설정도 있다.
        * behavior : Scale up, Scale down 하는 과정에서 동작을 정의하는 것이다. stabilizationWindowsSeconds은 정해진 시간 만큼 지켜본 후 적용할 것인지 셋업하는 부분이다.
        * [공식문서](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/)에 좀더 다양한 설정 방법이 존재한다.
```YAML
apiVersion: autoscaling/v2beta2
kind: HorizontalPodAutoscaler
metadata:
  name: phh-fo-hpa
  namespace: phh-test-fo
spec:
  scaleTargetRef:
    apiVersion: argoproj.io/v1alpha1
    kind: Rollout
    name: phh-fo
  minReplicas: 1
  maxReplicas: 4
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Pods
        value: 1
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100
        periodSeconds: 60
```

메트릭 관련해서 설정 잡는 방법
```YAML
  metrics:
  - type: Resource
    resource:
      name: memory
      target:
        type: AverageValue
        averageValue: 500Mi
```

```YAML
type: Pods
pods:
  metric:
    name: packets-per-second
  target:
    type: AverageValue
    averageValue: 1k
```

여러개를 메트릭으로 설정하는 예시
```YAML
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: php-apache
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: php-apache
  minReplicas: 1
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
  - type: Pods
    pods:
      metric:
        name: packets-per-second
      target:
        type: AverageValue
        averageValue: 1k
  - type: Object
    object:
      metric:
        name: requests-per-second
      describedObject:
        apiVersion: networking.k8s.io/v1
        kind: Ingress
        name: main-route
      target:
        type: Value
        value: 10k
status:
  observedGeneration: 1
  lastScaleTime: <some-time>
  currentReplicas: 1
  desiredReplicas: 1
  currentMetrics:
  - type: Resource
    resource:
      name: cpu
    current:
      averageUtilization: 0
      averageValue: 0
  - type: Object
    object:
      metric:
        name: requests-per-second
      describedObject:
        apiVersion: networking.k8s.io/v1
        kind: Ingress
        name: main-route
      current:
        value: 10k
```

<br>

### 2024-08-06 hpa 이슈
* 현상
    * hpa에서 `FailedGetResourceMetric`의 에러가 발생함
        * failed to get cpu utilization. did not receive metrics for targetd pods (pods might be unready)
        * invalid metrics ( 1 invalid out of 2), first error is: failed to get cpu resource metirc value: failed to get cpu utilization. did not receive metrics for targeted pods ( pods might be unready )
    * rollout에서 특정 1 pod가 계속 특정 Pod가 생성/삭제가 지속 반복되다가 정상화 됨

<br>

* 원인분석 방법
    * eks config를 update하여 해당 클러스터의 kubectl get nodes or pods를 수행하여 해당 인프라의 사용량을 체크한다.
    * 현재 Metric으로 수집되는 지표와 해당 지표의 값이 정상적으로 조회 되고 있는지 확인을 한다.
    * yaml 파일에 정의한 Metric 기준을 살펴본다.

```SHELL
# 아래 명령어 순차 실행
kubectl get --raw /api/v1/nodes/nodename/proxy/stats/summary
kubectl top nodes
kubectl top pods -A
kubectl get pods -n kube-system
kubectl describe hpa <deployment name>
```

마지막 명령어를 실행하면 현재 실행중인 조건의 상태도 조회가 된다.
```SHELL
Name:                           cm-test
Namespace:                      prom
Labels:                         <none>
Annotations:                    <none>
CreationTimestamp:              Fri, 16 Jun 2017 18:09:22 +0000
Reference:                      ReplicationController/cm-test
Metrics:                        ( current / target )
  "http_requests" on pods:      66m / 500m
Min replicas:                   1
Max replicas:                   4
ReplicationController pods:     1 current / 1 desired
Conditions:
  Type                  Status  Reason                  Message
  ----                  ------  ------                  -------
  AbleToScale           True    ReadyForNewScale        the last scale time was sufficiently old as to warrant a new scale
  ScalingActive         True    ValidMetricFound        the HPA was able to successfully calculate a replica count from pods metric http_requests
  ScalingLimited        False   DesiredWithinRange      the desired replica count is within the acceptable range
Events:
```

<br>

* 후속조치
    * 메트릭 설정 값을 다채롭게 건다.
    * 걸린 메트릭 지표가 잘 수집되는지/그에 따라 hpa가 정상 동작하는지 테스트를 진행한다.
    * eks pod 자체의 모니터링 수단을 확보한다.
    * behavior 부분 설정을 잡아서 생성과 종료 흐름을 제어한다.
    * metric server version도 한번 체크해본다. [kubernetes-sigs/metrics-server 레포의 issue#923](https://github.com/kubernetes-sigs/metrics-server/issues/923)를 보면 0.5.2에서는 CPU resources를 포함하지 않는다는 답변도 있다.